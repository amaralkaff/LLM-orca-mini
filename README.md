# Chat with LLM

A simple web application to chat with a large language model (LLM) using the Orca-mini model.

## Prerequisites

- Node.js (version 14 or higher)
- Bun (for running the development server)
- Orca-mini model and Ollama server running locally

## Installation

1. Clone the repository and navigate to the project directory:

   ```bash
   git clone https://github.com/yourusername/your-repo-name.git
   cd your-repo-name
   ```

2. Install dependencies:

   ```bash
   bun install
   ```

## Running the Application

1. Start the backend server:

   ```bash
   bun run server.js
   ```

2. Start the frontend development server:

   ```bash
   bun run dev
   ```

3. Open your browser and go to `http://localhost:5173`.

## Usage

- Type a question in the input field and press Enter or click "Ask".
- The response from the LLM will appear below your question.
